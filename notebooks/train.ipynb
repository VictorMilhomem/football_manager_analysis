{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63dd13d4-2fd3-46f9-8f8c-20f0df356f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7ea196-c3b0-45f7-b3c3-21627841be01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    def __init__(self, filepath, SEED=42):\n",
    "        self.filepath = filepath\n",
    "        self.dataset = pd.read_csv(self.filepath)\n",
    "        self.SEED = SEED\n",
    "        np.random.seed(SEED)\n",
    "    \n",
    "    def clean_data(self, columns: list):\n",
    "        self.dataset = self.dataset.drop(columns=columns)\n",
    "    \n",
    "    def encode(self, columns: list):\n",
    "        # Encode the labels\n",
    "        ohe = OneHotEncoder()\n",
    "        encoded = ohe.fit_transform(self.dataset[columns]).toarray()\n",
    "        columns = ohe.get_feature_names_out(columns)\n",
    "        encoded_df = pd.DataFrame(encoded, columns=columns)\n",
    "        self.dataset = pd.concat([self.dataset, encoded_df], axis=1)\n",
    "        self.dataset = dataset.drop(columns=columns)\n",
    "    \n",
    "    def normalize(self, columns: list):\n",
    "        # Normalize the dataset\n",
    "        norm = StandardScaler()\n",
    "        norm_ = norm.fit_transform(self.dataset[columns])\n",
    "        norm_df = pd.DataFrame(norm_, columns=[col + \"_norm\" for col in columns])\n",
    "        self.dataset = pd.concat([self.dataset, norm_df], axis=1)\n",
    "        self.dataset = self.dataset.drop(columns=columns)\n",
    "    \n",
    "    def train_split(self, X, y, test_size=0.3):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X,\n",
    "                                                                                y,\n",
    "                                                                                test_size=test_size,\n",
    "                                                                                random_state=self.SEED\n",
    "                                                                               )\n",
    "    \n",
    "    def train(self, model,baseline=None,feature_selection=False):\n",
    "        np.random.seed(self.SEED)\n",
    "        if feature_selection:\n",
    "            rfecv = RFECV(estimator=model, cv=5, scoring='r2', random_state=self.SEED)\n",
    "            rfecv.fit(self.X_train, self.y_train)\n",
    "            self.X_train_rfecv = rfecv.transform(self.X_train)\n",
    "            self.X_test_rfecv = rfecv.transform(self.X_test)\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(self.X_train_rfecv, self.y_train)\n",
    "            # Test the model\n",
    "            self.dummy()\n",
    "            self.test(model, feature_selection)\n",
    "            return model\n",
    "        \n",
    "        # Train the model without features selection\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        # Test the model\n",
    "        self.test(model, feature_selection)\n",
    "        if baseline != None:\n",
    "           print(f\"Baseline Score: {baseline} %\") \n",
    "        self.dummy()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def test(self, model, feature_selection=False, show=True):\n",
    "        if feature_selection:\n",
    "            # Test the model\n",
    "            y_pred = model.predict(self.X_test_rfecv)\n",
    "        else:\n",
    "            y_pred = model.predict(self.X_test)\n",
    "        # Check the accuracy using the R2 Score\n",
    "        acc = r2_score(self.y_test, y_pred) * 100\n",
    "        if show: print(f\"R2 Score: {acc} %\")\n",
    "        return acc\n",
    "    \n",
    "    def dummy(self):\n",
    "        # Creating a baseline\n",
    "        dummy_regressor = DummyRegressor(strategy=\"mean\")\n",
    "        dummy_regressor.fit(self.X_train, self.y_train)\n",
    "        y_pred = dummy_regressor.predict(self.X_test)\n",
    "        acc = r2_score(self.y_test, y_pred) * 100\n",
    "        print(f\"Dummy Regressor R2 Score: {acc} %\")    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63987bdd-f5f5-42a1-b7c8-44dad63c3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Random Forest Regressor\n",
    "\n",
    "fm = Utils(\"../FM 2023.csv\")\n",
    "fm.clean_data(columns=[\"Rental club\",\n",
    "                                \"Salary\",\n",
    "                                \"Values\",\n",
    "                                \"Race\",\n",
    "                                \"UID\", \n",
    "                                \"Date of birth\",\n",
    "                                \"Colour of skin\",\n",
    "                                \"RCA\",\n",
    "                                \"Race\",\n",
    "                                \"Club\",\n",
    "                                \"Nationality\",\n",
    "                                \"Name\",\n",
    "                                \"Position\",\n",
    "                               \"Current reputation\", \n",
    "                               \"Domestic reputation\",\n",
    "                               \"World reputation\"\n",
    "                               ]\n",
    "             )\n",
    "\n",
    "fm.normalize(columns=fm.dataset.columns)\n",
    "def train_ca(model, baseline=None):\n",
    "    global fm\n",
    "    # Function train a model for Current Ability prediction\n",
    "    # The X values cannot have the ca_norm without the pa_norm to avoid overfit\n",
    "    X = fm.dataset.drop(columns=[\"ca_norm\", \"pa_norm\"], axis=1)\n",
    "    y = fm.dataset['ca_norm']\n",
    "    fm.train_split(X, y)\n",
    "    return fm.train(model=model, baseline=baseline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0793bdb-6683-4b3f-8617-cab06d9c32cb",
   "metadata": {},
   "source": [
    "# Training a Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536376b7-d377-4382-a39d-6c6dbbc0b731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 84.42058122805432 %\n",
      "Baseline Score: 84.41210126314476 %\n",
      "Dummy Regressor R2 Score: -0.02595916467142967 %\n"
     ]
    }
   ],
   "source": [
    "#baseline = RandomForestRegressor(n_estimators=3000, n_jobs=-1, max_depth=50, max_leaf_nodes=55)\n",
    "#without_reputation_baseline = RandomForestRegressor(n_estimators=2000, n_jobs=-1, max_depth=10)\n",
    "model = RandomForestRegressor(n_estimators=2000, n_jobs=-1, max_depth=10)\n",
    "model = train_ca(model, baseline=84.41210126314476)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cf2131b-5f33-4957-b37c-9d962bea3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 91.76651445710918 %\n",
      "Baseline Score: 91.76651445710918 %\n",
      "Dummy Regressor R2 Score: -0.02595916467142967 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\anaconda3\\envs\\footballmanager_analysis\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "model = LinearSVR()\n",
    "model = train_ca(model, baseline=91.76651445710918)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "972b1f4e-c121-4747-b71d-dfbcfa602390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 95.52816097530203 %\n",
      "Baseline Score: 95.52816097530203 %\n",
      "Dummy Regressor R2 Score: -0.02595916467142967 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import NuSVR\n",
    "\n",
    "model = NuSVR()\n",
    "model = train_ca(model, baseline=95.52816097530203)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9440808-84f0-4428-b272-8c6550ebee7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 95.2074077468832 %\n",
      "Dummy Regressor R2 Score: -0.02595916467142967 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model = SVR()\n",
    "model = train_ca(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f8c9c6e-4459-47b0-b970-1d2337add5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 91.70875802721275 %\n",
      "Dummy Regressor R2 Score: -0.02595916467142967 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "model = SGDRegressor()\n",
    "model = train_ca(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
